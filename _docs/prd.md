# Updated Product Requirements Document (PRD): The Testing Agent

## 1. Introduction & Purpose
Developers using AI coding assistants like Claude face a significant challenge in the feedback loop. The process of testing generated code and reporting back issues—which involves manually taking screenshots, copying console logs, describing user interactions, and inspecting DOM elements—is inefficient, tedious, and error-prone.

The **Testing Agent** is a new software tool designed to automate this entire feedback process. Built on the **Claude Code SDK**, this agent interprets test scripts generated by the primary AI assistant, executes them using a browser automation framework, meticulously documents every step, and provides intelligent, context-aware feedback upon request.

## 2. Goals & Objectives
*   **Primary Goal:** To create a seamless, automated testing and feedback loop between a developer and their AI coding assistant.
*   **Objectives:**
    *   Automate the execution of user-flow tests for web applications.
    *   Eliminate the developer's manual effort in capturing and reporting bugs or visual states.
    *   Provide the AI assistant with precise, rich data (visuals, logs, network activity) to diagnose issues effectively.
    *   Intelligently filter and deliver only relevant information to the AI, conserving its context window and token usage, by leveraging custom agent capabilities.

## 3. Features & Functionality
*   **Custom Agent Architecture:** The system will be implemented as a **Custom Agent** within the Claude Code SDK framework, allowing for specialized behavior, dedicated tools, and a managed context.
*   **Automated Test Execution:** The agent will use **Tool Calling** to execute Playwright test scripts generated by the primary AI assistant, defining the exact user flow to be tested.
*   **Transparent Test Execution:**
    *   The agent runs tests in a visible browser window (headed mode) by default, allowing developers to watch the automated flow in real-time. This provides instant visual feedback and builds confidence in the test's execution path.
*   **Comprehensive Data Capture:**
    *   **Interaction Logging:** The agent will log every interaction from the script (e.g., clicks, hovers, text input) with a precise timestamp.
    *   **Visual Documentation:** It will automatically take screenshots before and after every key interaction.
    *   **Console & Network Monitoring:** The agent will capture browser console logs and network tab activity.
    *   **DOM Inspection:** The agent can inspect DOM elements to verify CSS properties when requested.
*   **Autonomous, On-Demand Reporting:**
    *   **Session Orchestration:** When a test starts, the agent opens or joins a Claude Code conversation and maintains it for the test lifecycle.
    *   **Automatic Post-Run Summary:** After execution, the agent posts a concise summary (status, `run_id`, artifact index) directly to Claude—no developer mediation.
    *   **NLU-Driven Tool Calls (No Copy/Paste):** Claude requests specifics in natural language (e.g., "console errors", "screenshot after submit"); the agent automatically fulfills these via tool calls and sends only the requested artifacts back into the same conversation.
    *   **Selective & Proactive:** The agent responds with minimal, relevant data and proactively surfaces critical console errors by default.

## 4. Technical Specification
*   **Core Framework:** The application will be built using the **Claude Code SDK (TypeScript)**, running as a Node.js process.
*   **Agent Definition:** A custom "Testing Agent" will be defined using YAML frontmatter, specifying its system prompt, capabilities, a restricted set of tools, and conversation/session wiring to Claude Code.
*   **Browser Automation & Data Capture:**
    *   **Playwright & Playwright MCP:** The agent will interface with a browser via the **Playwright MCP (Model Context Protocol) server**. This provides the "hands and eyes" for the agent, enabling it to:
        *   Run automation scripts.
        *   Access the browser's Developer Tools API.
        *   Capture console events, network requests, and screenshots.
        *   Generate a comprehensive trace file for each test run.
*   **Agent Logic & Tooling:**
    *   **Test Executor Tool:** A primary tool function (`run_test(script_path)`) manages Playwright execution in headed mode and orchestrates artifact capture.
    *   **Data Retrieval Tools:** A suite of tool functions (`get_artifact` with `type: screenshot|console|network`, and filters) returns only the requested artifacts from the run directory.
    *   **Autonomous Bridge:** An agent runtime component posts the post-run summary and automatically serves Claude’s follow-up requests via tool calls—no human copy/paste.
    *   **Data Storage:** For each test run, the agent creates a time-stamped directory containing all artifacts: screenshots (named by action/timing), `actions.json`, `console.log`, `network.log`, and the Playwright trace file.
